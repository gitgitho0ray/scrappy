{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10timesdotcom_Scrappy-Doo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnumS8gHtu2vpvzQOlgIga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitgitho0ray/scrappy/blob/master/10_times_scrappy_doo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vygkQneWaJRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from time import strptime\n",
        "from time import sleep\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from calendar import monthrange\n",
        "from datetime import timedelta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcjSFPZpM4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EventDate():\n",
        "\n",
        "    def __init__(self, eventdate):\n",
        "\n",
        "        if len(eventdate) == 4:\n",
        "            sday=int(strptime(eventdate[0],'%d').tm_mday)\n",
        "            month=int(strptime(eventdate[2],'%b').tm_mon)\n",
        "            eday=int(strptime(eventdate[1],'%d').tm_mday)\n",
        "            year=int(strptime(eventdate[-1],'%Y').tm_year)\n",
        "            self.startdate = datetime.date(datetime(year, month, sday))\n",
        "            self.enddate = datetime.date(datetime(year, month, eday))\n",
        "\n",
        "        elif len(eventdate) == 5:\n",
        "            sday=int(strptime(eventdate[0],'%d').tm_mday)\n",
        "            smonth=int(strptime(eventdate[1],'%b').tm_mon)\n",
        "            eday=int(strptime(eventdate[2],'%d').tm_mday)\n",
        "            emonth=int(strptime(eventdate[3],'%b').tm_mon)\n",
        "            year=int(strptime(eventdate[-1],'%Y').tm_year)\n",
        "            self.startdate = datetime.date(datetime(year, smonth, sday))\n",
        "            self.enddate = datetime.date(datetime(year, emonth, eday))\n",
        "\n",
        "        else:\n",
        "            sday=int(strptime(eventdate[0],'%d').tm_mday)\n",
        "            month=int(strptime(eventdate[1],'%b').tm_mon)\n",
        "            eday=int(strptime(eventdate[0],'%d').tm_mday)\n",
        "            year=int(strptime(eventdate[-1],'%Y').tm_year)\n",
        "            self.startdate = datetime.date(datetime(year, month, sday))\n",
        "            self.enddate = datetime.date(datetime(year, month, eday))\n",
        "        \n",
        "class SearchDate():   \n",
        "\n",
        "    def __init__(self,today='',endofweek='',endofthemonth=''):\n",
        "        self.today=str(datetime.now().date())\n",
        "        self.addoneweek=str((datetime.now().date()+timedelta(days=7)))\n",
        "        self.endofthemonth=str(datetime(datetime.now().year,datetime.now().month,monthrange(datetime.now().year, datetime.now().month)[1]).date())\n",
        "\n",
        "class ScrappyDoo():\n",
        "\n",
        "    def __init__(self,url):\n",
        "        self.url = url\n",
        "\n",
        "    def get_content(self):\n",
        "\n",
        "        def get_html(url, params=None):\n",
        "            h = {'user-agent':'Mozilla/5.0 (Macintosh; Intel) Gecko/20100101 Firefox/74.0'}\n",
        "            response = requests.get(self.url,params=params,headers=None)\n",
        "            return response.text\n",
        "\n",
        "        soup = BeautifulSoup(get_html(url), 'html.parser')\n",
        "        items = soup.find_all('tr', class_='box')\n",
        "        events=[i.find('a', {'target':'_blank'}).get('href') for i in items if i.find('a', {'target':'_blank'}) !=None]\n",
        "        return events\n",
        "        \n",
        "\n",
        "    def parse():\n",
        "        html = get_html(url)\n",
        "        if html.status_code == 200:\n",
        "            get_content(html.text)\n",
        "        else:\n",
        "            print('error')\n",
        "        return html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFWki56WGcoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    def get_html(url, params=None):\n",
        "        h = {'user-agent':'Mozilla/5.0 (Macintosh; Intel) Gecko/20100101 Firefox/74.0'}\n",
        "        response = requests.get(url,params=params,headers=None)\n",
        "        return response.text\n",
        "        \n",
        "    date = SearchDate()\n",
        "    url = f'https://10times.com/canada/conferences?month=today&datefrom={date.today}&dateto={date.today}'\n",
        "    links = ScrappyDoo(url = url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLmQ4VLfhOHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datalist=[]\n",
        "for url in links.get_content(): \n",
        "    print(url)\n",
        "    soup = BeautifulSoup(get_html(url), 'html.parser')\n",
        "\n",
        "    #event info \n",
        "    eventname = soup.find('h1').get_text()\n",
        "\n",
        "    try:\n",
        "        organizer = soup.find('h3',{'id':'org-name'}).get_text().split('\\n')[0]\n",
        "    except AttributeError:\n",
        "        organizer = soup.find('h3').get_text().split('\\n')[0]\n",
        "\n",
        "    description = soup.find('p', class_=\"desc mng word-break\").get_text(strip=True)\n",
        "    location=[i.get_text() for i in soup.find_all('p') if i.find('span') != None][0]\n",
        "    eventdate = EventDate(soup.select('span[content]')[0].get_text().replace('-','').split())\n",
        "    rawtables = [i.find('table',class_='table noBorder mng').find_all('td') for i in soup.find_all('div', class_='row11')]\n",
        "    info=[rawtables[0][i].get_text().split(\" \",1) for i in range(len(rawtables[0]))]\n",
        "    infodata=[i[1].strip('\\n').strip() for i in info[:4]]\n",
        "    time = [\" \".join(i[:2]) for i in [i.split() for i in infodata[0].split('-')]] # time \n",
        "    participants =(re.findall(r\"[0-9]+\\s-\\s[0-9]+ | [0-9]+\", infodata[2]))[0].strip()\n",
        "    tags = (', '.join(infodata[3].replace('Type','').replace('&','').split()))\n",
        "    \n",
        "    #attendees data \n",
        "    users = soup.find('div', class_=\"visitor clearfix\")\n",
        "    attendeedata=[]\n",
        "    if users is None:\n",
        "        attendeedata.append(None)\n",
        "    else:\n",
        "        try:\n",
        "            for i in soup.find('div', class_=\"visitor clearfix\"):\n",
        "                try:\n",
        "                    attendeedata.append([i.find('h4').get_text(),' '.join(i.get_text().replace('Connect','').split()[-2:]),i.find('a').get('href')])\n",
        "                except AttributeError:\n",
        "                    continue\n",
        "        except TypeError:\n",
        "            continue\n",
        "    \n",
        "    datalist.append([url,\n",
        "                   eventname,\n",
        "                   organizer,\n",
        "                   description,\n",
        "                   location,\n",
        "                   eventdate.startdate,\n",
        "                   eventdate.enddate,\n",
        "                   time[0],\n",
        "                   time[1],\n",
        "                   tags,\n",
        "                   participants,\n",
        "                   attendeedata])\n",
        "    print('Processed')\n",
        "\n",
        "df = pd.DataFrame(datalist,columns=['Link',\n",
        "                                    'EventName',\n",
        "                                    'Organizer',\n",
        "                                    'Description',\n",
        "                                    'Address',\n",
        "                                    'StartDate',\n",
        "                                    'EndDate',\n",
        "                                    'StartTime',\n",
        "                                    'EndTime',\n",
        "                                    'Tags',\n",
        "                                    'ExpectedParticipants',\n",
        "                                    'AttendeeData'])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaMniD7mqJYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}